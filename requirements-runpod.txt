runpod
# Core HF stack for GLM-OCR (no vLLM) â€” cache buster: bump to force pip layer rebuild
torch==2.3.0
torchvision==0.18.0
transformers @ git+https://github.com/huggingface/transformers.git
accelerate
Pillow
requests
